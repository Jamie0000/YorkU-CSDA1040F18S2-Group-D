---
title: "CDSA1040Project1"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Loading the Packages

```{r}
# Importing libraries

library(data.table)           
library(readxl)               
library(tidyverse)
library(lubridate)
library(skimr)                
library(knitr)                
library(treemap)
```




## Loading and Inspecting the Data
```{r}
# import raw data file and trim leading and trailing whitespaces
retail <- read_excel("Online_Retail.xlsx", trim_ws = TRUE)
```
##

The dataset consists of just over 541,909 observations spread across 8 variables. A few Descriptions and several CustomerIDs are missing and there are also some odd negatives Quantity and UnitPrice that would be worth investigating. It’s also worth noting that InvoiceDate is of POSIXct format, from which information about Date and Time of purchase can be extracted.

Dataset variables description

InvoiceNo   (Invoice number) - 6-digit integral number. Indicates cancellation if starts with ‘C’

StockCode   (Product item code) - 5-digit integral number

Description (Product (item)) - name

Quantity	   (Quantities of each product (item) per transaction) - Numeric

InvoiceDate (Invoice Date and Time) - when each transaction was generated

UnitPrice	 (Unit price) - Numeric, Product price per unit in sterling

CustomerID	 (Customer number) - 5-digit integral number unique to each customer

Country	   (Country name) -  The name of the country where each customer resides


```{r}
# First glance at the data
retail %>%  skim()
```

##
Cancellations: The Variables Description, if the InvoiceNo starts with letter ‘C’, it indicates a cancellation

```{r}
retail %>% 
  filter(grepl("C", retail$InvoiceNo)) %>% 
  summarise(Total = n())
```
```{r}
# Cancellations invoice are not needed for the analysis

retail  <- retail %>% 
  filter(!grepl("C", retail$InvoiceNo)) 

# Total row count - 532,621
```

## Negative Quantities

When filtering by non positive Quantity, the manually entered Description shows

e.g.“thrown away”, “Unsaleable”, “damaged”,“?”)

and UnitPrice is also set to zero for all of them, it is safe to assume that these were adjustments codes.


```{r}
retail %>% 
  filter(Quantity <= 0) %>% 
  group_by(Description, UnitPrice) %>% 
  summarise(count =n()) %>%
  arrange(desc(count)) %>% 
  ungroup()
```

```{r}
# Eliminating all rows with non-positive Quantity.
retail  <- retail %>% 
  filter(Quantity > 0)

# Total row count - 531,285
```

##Non-Product StockCodes
There are few non-product related stock codes in dataset ie. Postage, Bank Charges, Gift Vouchers, etc.


```{r}
# Non-product related codes
stc <- c('AMAZONFEE', 'BANK CHARGES', 'C2', 'DCGSSBOY', 'DCGSSGIRL',
         'DOT', 'gift_0001_', 'PADS', 'POST')
```


```{r}
retail %>%  
  filter(grepl(paste(stc, collapse="|"), StockCode))  %>% 
  group_by(StockCode, Description) %>% 
  summarise(count =n()) %>%
  arrange(desc(count)) %>% 
  ungroup()
```

## Eliminating Non-product stock codes
```{r}
retail <- filter(retail, !grepl(paste(stc, collapse="|"), StockCode))

# Total row count - 529,228
```

## Description
Working on the Description field, there are an additional 50 manually entered annotations that need removing. I one case an employee has even vented out their frustration at one of their co-workers (“alan hodge cant mamage this section”), with misspelling and all!

```{r}
# Additional adjustment codes to remove
descr <- c( "check", "check?", "?", "??", "damaged", "found", 
            "adjustment", "Amazon", "AMAZON", "amazon adjust", 
            "Amazon Adjustment", "amazon sales", "Found", "FOUND",
            "found box", "Found by jackie ", "Found in w/hse", "dotcom",
            "dotcom adjust", "allocate stock for dotcom orders ta", "FBA",
            "Dotcomgiftshop Gift Voucher £100.00", "on cargo order",
            "wrongly sold (22719) barcode", "wrongly marked 23343",
            "dotcomstock", "rcvd be air temp fix for dotcom sit", "Manual",
            "John Lewis", "had been put aside", "for online retail orders",  
            "taig adjust", "amazon", "incorrectly credited C550456 see 47",
            "returned", "wrongly coded 20713", "came coded as 20713", 
            "add stock to allocate online orders", "Adjust bad debt",
            "alan hodge cant mamage this section", "website fixed",
            "did  a credit  and did not tick ret", "michel oops",
            "incorrectly credited C550456 see 47", "mailout", "test",
            "Sale error",  "Lighthouse Trading zero invc incorr", "SAMPLES",
            "Marked as 23343", "wrongly coded 23343","Adjustment", 
            "rcvd be air temp fix for dotcom sit", "Had been put aside."
          )
```


```{r}
# Filtering out the unwanted entries.
retail <- retail %>% 
  filter(!Description %in% descr)

# Total row count - 528,732
```


```{r}
# Eliminating NAs in Descriptions
sum(is.na(retail$Description))
```


```{r}
retail <- retail %>% 
  filter(!is.na(Description))

# Total row count - 528,148
```


```{r}
# Verify Customer NAs entries
retail$CustomerID %>%  
  skim()
```

## 
For the analysis, need to arrange data in a user-item format, where “users” can be either customers or orders. Given that there are almost 5 times as many Orders as there are Customers, 

We use InvoiceNo for orders in the analysis, which should make for a richer information set.

```{r}
sapply(retail[,c('InvoiceNo','CustomerID')], function(x) length(unique(x)))
```



```{r}
retail <- retail %>%
# Setting 'Description' and 'Country' as factors
  mutate(Description = as.factor(Description)) %>%
  mutate(Country = as.factor(Country)) %>% 
# Changing 'InvoiceNo' type to numeric
  mutate(InvoiceNo = as.numeric(InvoiceNo)) %>% 
# Extracting 'Date' and 'Time' from 'InvoiceDate'
  mutate(Date = as.Date(InvoiceDate)) %>% 
  mutate(Time = as.factor(format(InvoiceDate,"%H:%M:%S"))) 

glimpse(retail)
```

# Exploratory Data Analysis

## Most Popular items
```{r}
retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  top_n(10, wt = count) %>%
  arrange(desc(count)) %>% 
  ggplot(aes(x = reorder(Description, count), y = count))+
  geom_bar(stat = "identity", fill = "royalblue", colour = "blue") +
  labs(x = "", y = "Top 10 Best Sellers") +
  coord_flip() +
  theme_grey(base_size = 12)
```
# Based on Top 10 Best sellar, The heart-shaped tea light holder is the most popular item.


```{r}
retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  mutate(pct=(count/sum(count))*100) %>% 
  arrange(desc(pct)) %>% 
  ungroup() %>% 
  top_n(10, wt=pct)
```
# Top 10 most sold products represent around 3% of total items sold by the company


# Time of day people buy more often.
# Lunchtime is the preferred time for shopping online, with the majority of orders places between 12 noon and 3pm.
```{r}
retail %>% 
  ggplot(aes(hour(hms(Time)))) + 
  geom_histogram(stat = "count",fill = "#E69F00", colour = "red") +
  labs(x = "Hour of Day", y = "") +
  theme_grey(base_size = 12)
```

## Day of the week people buy more often.
# Orders peaks on Thursdays with no orders processed on Saturdays.
```{r}
retail %>% 
  ggplot(aes(wday(Date, 
                  week_start = getOption("lubridate.week.start", 1)))) + 
  geom_histogram(stat = "count" , fill = "forest green", colour = "dark green") +
  labs(x = "Day of Week", y = "") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7),
                     labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
  theme_grey(base_size = 14)
```


## Basket Count
# Customers typically purchase between 2 and 15 items, with a peak at 2.
```{r}
retail %>% 
  group_by(InvoiceNo) %>% 
  summarise(n = mean(Quantity)) %>%
  ggplot(aes(x=n)) +
  geom_histogram(bins = 100000, fill = "purple", colour = "black") + 
  coord_cartesian(xlim=c(0,100)) +
  scale_x_continuous(breaks=seq(0,100,10)) +
  labs(x = "Average Number of Items per Purchase", y = "") +
  theme_grey(base_size = 14)
```
# Comments
## This concludes the data preparation and visualisation part of the our project. We removed Cancellations, eliminated negative Quantity and UnitPrice, got rid of NAs in Description and created two new variables, Date and Time. A total of 13,761 rows (roughly 2.5% of the initial count) were discarded and the dataset has now 528,148 observations.



```{r}
retail <- retail %>% 
# create unique identifier
    mutate(InNo_Desc = paste(InvoiceNo, Description, sep = ' ')) 
# filter out duplicates and drop unique identifier
    retail <- retail[!duplicated(retail$InNo_Desc), ] %>% 
    select(-InNo_Desc)

```
