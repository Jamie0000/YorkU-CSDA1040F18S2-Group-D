---
title: "CDSA1040Project1"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Abstract
Our objective for this assignment is to produce a product recommending application.  Our success criteria will be determined by the completeness by which the code and application user interface both selects and displays the most commonly associated purchased items, based on initial selection(s) of pre-determined items.  This R Shiny application could be used in a physical retail setting to determine product layout but is ideally suited for an online purchasing environment to help increase sales by recommending additional items for consideration during a user's purchase experience.

## Introduction and Discussion

With the proliferation of online shopping, retailers and alternative vendors (e-retailers) such as Alibaba and Amazon rely heavily on recommending items or products beyond the consumer's original purchase.  These recommendations are achieved through a myriad of observations, pattern discovery, and ultimately data science analytics.

For our project, we used two different models, collaborative filtering (part 1) and Apriori (part 2).  After reviewing both methods, we decided that our application would be powered by the collaborative filtering method, specifically an item-based collaborative filtering model.

## Loading the Packages

```{r}
# Importing libraries

library(data.table)           
library(readxl)               
library(tidyverse)
library(lubridate)
library(skimr)                
library(knitr)                
library(treemap)
```

## Data Exploration
For our data source, we used a dataset obtained from the UCI Machine Learning Repository of Online Retail transactions from http://archive.ics.uci.edu/ml/datasets/online+retail.  The multi-national dataset consists of 541,909 transactions of unique, all-occasion gifts that occurred between January 12, 2010 and September 12, 2011, and is spread across 8 variables defined as follows:

1.	InvoiceNo: Invoice number.  Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. 
2.	StockCode: Product (item) code.  Nominal, a 5-digit integral number uniquely assigned to each distinct product. 
3.	Description: Product (item) name.  Nominal. 
4.	Quantity: The quantities of each product (item) per transaction.  Numeric.	
5.	InvoiceDate: Invice Date and time.  Numeric, the day and time when each transaction was generated. 
6.	UnitPrice: Unit price.  Numeric, Product price per unit in sterling. 
7.	CustomerID: Customer number.  Nominal, a 5-digit integral number uniquely assigned to each customer. 
8.	Country: Country name.  Nominal, the name of the country where each customer resides.

A few Descriptions and several CustomerIDs are missing and there are also some odd negatives Quantity and UnitPrice that would be worth investigating. It is also worth noting that InvoiceDate is of POSIXct format, from which information about Date and Time of purchase can be extracted.

## Loading and Inspecting the Data
```{r}
# import raw data file and trim leading and trailing whitespaces
retail <- read_excel("C:/Users/Rob/Desktop/ROBs STUFF/YorkU - Big Data Analytics (BDA F18_S2)/CSDA1040 Advanced Methods of Data Analysis/TEAM PROJECTS/Assignment 1/Online Retail.xlsx", trim_ws = TRUE)
```

```{r}
# First glance at the data
retail %>%  skim()
```

##
Cancellations: The Variables Description, if the InvoiceNo starts with letter C, it indicates a cancellation

```{r}
retail %>% 
  filter(grepl("C", retail$InvoiceNo)) %>% 
  summarise(Total = n())
```
```{r}
# Cancellations invoice are not needed for the analysis

retail  <- retail %>% 
  filter(!grepl("C", retail$InvoiceNo)) 

# Total row count - 532,621
```

## Negative Quantities

When filtering by non positive Quantity, the manually entered Description shows

e.g.“thrown away”, “Unsaleable”, “damaged”,“?”)

and UnitPrice is also set to zero for all of them, it is safe to assume that these were adjustments codes.


```{r}
retail %>% 
  filter(Quantity <= 0) %>% 
  group_by(Description, UnitPrice) %>% 
  summarise(count =n()) %>%
  arrange(desc(count)) %>% 
  ungroup()
```

```{r}
# Eliminating all rows with non-positive Quantity.
retail  <- retail %>% 
  filter(Quantity > 0)

# Total row count - 531,285
```

##Non-Product StockCodes
There are few non-product related stock codes in dataset ie. Postage, Bank Charges, Gift Vouchers, etc.


```{r}
# Non-product related codes
stc <- c('AMAZONFEE', 'BANK CHARGES', 'C2', 'DCGSSBOY', 'DCGSSGIRL',
         'DOT', 'gift_0001_', 'PADS', 'POST')
```


```{r}
retail %>%  
  filter(grepl(paste(stc, collapse="|"), StockCode))  %>% 
  group_by(StockCode, Description) %>% 
  summarise(count =n()) %>%
  arrange(desc(count)) %>% 
  ungroup()
```

## Eliminating Non-product stock codes
```{r}
retail <- filter(retail, !grepl(paste(stc, collapse="|"), StockCode))

# Total row count - 529,228
```

## Description
Working on the Description field, there are an additional 50 manually entered annotations that need removing. I one case an employee has even vented out their frustration at one of their co-workers (“alan hodge cant mamage this section”), with misspelling and all!

```{r}
# Additional adjustment codes to remove
descr <- c( "check", "check?", "?", "??", "damaged", "found", 
            "adjustment", "Amazon", "AMAZON", "amazon adjust", 
            "Amazon Adjustment", "amazon sales", "Found", "FOUND",
            "found box", "Found by jackie ", "Found in w/hse", "dotcom",
            "dotcom adjust", "allocate stock for dotcom orders ta", "FBA",
            "Dotcomgiftshop Gift Voucher £100.00", "on cargo order",
            "wrongly sold (22719) barcode", "wrongly marked 23343",
            "dotcomstock", "rcvd be air temp fix for dotcom sit", "Manual",
            "John Lewis", "had been put aside", "for online retail orders",  
            "taig adjust", "amazon", "incorrectly credited C550456 see 47",
            "returned", "wrongly coded 20713", "came coded as 20713", 
            "add stock to allocate online orders", "Adjust bad debt",
            "alan hodge cant mamage this section", "website fixed",
            "did  a credit  and did not tick ret", "michel oops",
            "incorrectly credited C550456 see 47", "mailout", "test",
            "Sale error",  "Lighthouse Trading zero invc incorr", "SAMPLES",
            "Marked as 23343", "wrongly coded 23343","Adjustment", 
            "rcvd be air temp fix for dotcom sit", "Had been put aside."
          )
```


```{r}
# Filtering out the unwanted entries.
retail <- retail %>% 
  filter(!Description %in% descr)

# Total row count - 528,732
```


```{r}
# Eliminating NAs in Descriptions
sum(is.na(retail$Description))
```


```{r}
retail <- retail %>% 
  filter(!is.na(Description))

# Total row count - 528,148
```


```{r}
# Verify Customer NAs entries
retail$CustomerID %>%  
  skim()
```

## 
For the analysis, need to arrange data in a user-item format, where “users” can be either customers or orders. Given that there are almost 5 times as many Orders as there are Customers, 

We use InvoiceNo for orders in the analysis, which should make for a richer information set.

```{r}
sapply(retail[,c('InvoiceNo','CustomerID')], function(x) length(unique(x)))
```



```{r}
retail <- retail %>%
# Setting 'Description' and 'Country' as factors
  mutate(Description = as.factor(Description)) %>%
  mutate(Country = as.factor(Country)) %>% 
# Changing 'InvoiceNo' type to numeric
  mutate(InvoiceNo = as.numeric(InvoiceNo)) %>% 
# Extracting 'Date' and 'Time' from 'InvoiceDate'
  mutate(Date = as.Date(InvoiceDate)) %>% 
  mutate(Time = as.factor(format(InvoiceDate,"%H:%M:%S"))) 

glimpse(retail)
```

# Exploratory Data Analysis

## Most Popular items
```{r}
retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  top_n(10, wt = count) %>%
  arrange(desc(count)) %>% 
  ggplot(aes(x = reorder(Description, count), y = count))+
  geom_bar(stat = "identity", fill = "royalblue", colour = "blue") +
  labs(x = "", y = "Top 10 Best Sellers") +
  coord_flip() +
  theme_grey(base_size = 12)
```
# Based on Top 10 Best sellar, The heart-shaped tea light holder is the most popular item.


```{r}
retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  mutate(pct=(count/sum(count))*100) %>% 
  arrange(desc(pct)) %>% 
  ungroup() %>% 
  top_n(10, wt=pct)
```
# Top 10 most sold products represent around 3% of total items sold by the company


# Time of day people buy more often.
# Lunchtime is the preferred time for shopping online, with the majority of orders places between 12 noon and 3pm.
```{r}
retail %>% 
  ggplot(aes(hour(hms(Time)))) + 
  geom_histogram(stat = "count",fill = "#E69F00", colour = "red") +
  labs(x = "Hour of Day", y = "") +
  theme_grey(base_size = 12)
```

## Day of the week people buy more often.
# Orders peaks on Thursdays with no orders processed on Saturdays.
```{r}
retail %>% 
  ggplot(aes(wday(Date, 
                  week_start = getOption("lubridate.week.start", 1)))) + 
  geom_histogram(stat = "count" , fill = "forest green", colour = "dark green") +
  labs(x = "Day of Week", y = "") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7),
                     labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
  theme_grey(base_size = 14)
```


## Basket Count
# Customers typically purchase between 2 and 15 items, with a peak at 2.
```{r}
retail %>% 
  group_by(InvoiceNo) %>% 
  summarise(n = mean(Quantity)) %>%
  ggplot(aes(x=n)) +
  geom_histogram(bins = 100000, fill = "purple", colour = "black") + 
  coord_cartesian(xlim=c(0,100)) +
  scale_x_continuous(breaks=seq(0,100,10)) +
  labs(x = "Average Number of Items per Purchase", y = "") +
  theme_grey(base_size = 14)
```
# Comments
## This concludes the data preparation and visualisation part of the our project. We removed Cancellations, eliminated negative Quantity and UnitPrice, got rid of NAs in Description and created two new variables, Date and Time. A total of 13,761 rows (roughly 2.5% of the initial count) were discarded and the dataset has now 528,148 observations.



```{r}
retail <- retail %>% 
# create unique identifier
    mutate(InNo_Desc = paste(InvoiceNo, Description, sep = ' ')) 
# filter out duplicates and drop unique identifier
    retail <- retail[!duplicated(retail$InNo_Desc), ] %>% 
    select(-InNo_Desc)

```
